## Семинар 1
### Задача 1

$H_0: p_1 = p_2$ против
$H_1: p_1 \ne p_2$

$\alpha = 0.05$, двусторонняя альтернатива

$\hat{p}_1 = 0.79$, $\hat{p}_2 = 0.85$,
$\hat{p} = 0.82$

$z_{набл} = 0.71$, $\text{pvalue} = 2\text{P}(Z > z_{набл}) = 2 \cdot 0.239 = 0.478$

$H_0$ не отвергается, если изменим тип альтернативы на левосторонюю, p-value сократится вдвое, но вывод не изменится.

В Python практически то же самое, чуть поточнее – можете проверить (по умолчанию двусторонняя альтернатива, 
далее сами можем изменить на левостороннюю):


```{python}
from statsmodels.stats.proportion import proportions_ztest

proportions_ztest(count = [30, 39], nobs = [38, 46])
proportions_ztest(count = [30, 39], nobs = [38, 46], alternative = "smaller")
```

### Задача 2

$H_0: p_1 = p_2$ против
$H_1: p_1 < p_2$

$\alpha = 0.1$, односторонняя альтернатива

$z_{набл} = 1.16$, $\text{pvalue} = \text{P}(Z > z_{набл}) = 0.122$, $H_0$ не отвергается

P.S. На мой взгляд, более логично было бы вычитать из первой доли вторую (к слову, в Python так), получать отрицательное 
значение статистики критерия, рассматривать P(Z < -1.16) или критическую область слева в отрицательной полуплоскости, но раз на лекции договорились вычитать 
из второй доли первую, пусть так и будет, p-value и вывод от этого не изменится. В любом случае, в симметричных распределениях 
не так важно, важно только отличать случай с ненаправленной (двусторонней) альтернативой от случая с направленной (односторонней) альтернативой. 

### Задача 3

$H_0: a_1 = a_2$ против $H_1: a_1 > a_2$ (если предположим, исходя из данных, что первая эффективнее)

$\alpha = 0.01$, односторонняя альтернатива

$t_{набл} = -0.4$, $\text{pvalue} = \text{P}(T < t_{набл}) \approx \text{P}(Z < t_{набл})\approx 0.34$

$H_0$ не отвергается

P.S. Тот же комментарий, что и выше. В Python из первого среднего вычитается второе, поэтому при решении в нём 
наблюдаемое значение статистики будет 0.4, и тогда $\text{pvalue} = \text{P}(T > 0.4)$. Можете убедиться:

```{python}
from scipy import stats

stats.ttest_ind_from_stats(mean1 = 3.8, std1 = 5.9 ** 0.5, 
                           mean2 = 3.6, std2 = 5.2 ** 0.5,
                           nobs1 = 55, nobs2 = 65, 
                           equal_var = True, alternative = "greater")
```

### Задача 4

$H_0: a_1 = a_2 \text{ }(\sigma^2_1 = \sigma^2_2)$ против
$H_1: a_1 \ne a_2 \text{ }(\sigma^2_1 = \sigma^2_2)$

$\alpha = 0.05$, двусторонняя альтернатива

$t_{набл} = -1.9$

$t_{крит} = t(\text{df}=12, \alpha = 0.025) = 2.18$

критическая область: (-∞; -2.18] ∪ [2.18; +∞)

точное $\text{pvalue} = 2\text{P}(T < t_{набл}) = 2 \cdot 0.041 = 0.082$, можем оценить его снизу – 
по таблице стандартного нормального распределения найдем 2P(Z < -1.9) = 0.0574 и заключим, что 2P(T < -1.9) ещё больше.

### Задача 5

$H_0: F = G$ против $H_1: F < G$ (так как значения второй выборки почти всегда больше)

$\alpha = 0.05$, односторонняя альтернатива

* ранги (выборка 1 + выборка 2 вместе):  1,  9, 5, 2, 14, 4, 7, 11, 15, 13, 6, 12, 10, 3, 8
* ранги для первой выборки (объёма $n = 8$): 1, 9, 5, 2, 14, 4, 7, 11
* ранги для второй выборки (объёма $n = 7$): 15, 13, 6, 12, 10, 3, 8

для критерия Уилкоксона c аппроксимацией нормальным распределением (вариант решения 1, его достаточно, пренебрежем маленьким объёмом выборок): 

* $W_{набл} = 67$ (сумма рангов для второй выборки c $n=7$, она меньше)
* $E(W) = 56$, $D(W) = 74.67$
* $W_{набл}^* = \frac{67-56}{\sqrt{74.67}} \approx 1.27 \sim  N(0, 1)$, $\text{pvalue} = \text{P}(Z > 1.27) = 0.102$, $H_0$ не отвергается

для критерия Манна-Уитни (вариант решения 2): 

* сумма рангов первой выборки $R_1 = 53$, сумма рангов второй выборки $R_2 = 67$
* U-значения для выборок: $U_1 = 39$, $U_2 = 17$
* $U_{набл} = \min(39, 17) = 17$, $U_{крит} = U(7, 8, 0.05) = 13$ (односторонняя альтернатива), $U_{набл} > U_{крит}$, $H_0$ не отвергается
  (меньшие значения U свидетельствуют о наличии различий, то есть против $H_0$, критическая область слева от 10)

В Python критерий Манна-Уитни реализуется схожим образом, просто в нём считается p-value (приближённое или точное), 
единственное, в выдаче на первом месте – не $U$ как выше (минимальное из двух), а $U_1$.

```{python}
from scipy import stats
  
stats.mannwhitneyu([50, 147, 117, 78, 192, 111, 142, 160], 
                   [205, 185, 134, 167, 155, 90, 144], alternative = "less")
```

### Задача 6

$H_0: F = G$ против $H_1: F \ne G$

$\alpha = 0.10$, двусторонняя альтернатива

* ранги (выборка 1 + выборка 2 вместе): 12.5, 15, 20, 19, 11, 7.5, 17, 12.5, 3, 6, 5, 22, 16, 14, 21, 2, 4, 7.5, 10, 1, 18, 9
* ранги для первой выборки (объёма $n = 11$): 12.5, 15, 20, 19, 11, 7.5, 17, 12.5, 3, 6, 5
* ранги для второй выборки (объёма $n = 11$): 22, 16, 14, 21, 2, 4, 7.5, 10, 1, 18, 9

для критерия Уилкоксона c аппроксимацией нормальным распределением (вариант решения 1, его достаточно, пренебрежем маленьким объёмом выборок): 

* $W_{набл} = 124.5$ (сумма рангов для второй выборки)
* $E(W) = 126.5$, $D(W) \approx 232$
* $W_{набл}^* = \frac{124.5-126.5}{\sqrt{232}} \approx -0.13 \sim  N(0, 1)$, $\text{pvalue} = 2\text{P}(Z < -0.13) = 0.8966$, $H_0$ не отвергается

для критерия Манна-Уитни (вариант решения 2): 

* сумма рангов первой выборки $R_1 = 128.5$, сумма рангов второй выборки $R_2 = 124.5$
* U-значения для выборок: $U_1 = 58.5$, $U_2 = 62.5$
* $U_{набл} = \min(58.5, 62.5) = 58.5$, $U_{крит} = U(11, 11, 0.05) = 34$, $U_{набл} > U_{крит}$, $H_0$ не отвергается
  (меньшие значения U свидетельствуют о наличии различий, то есть против $H_0$, критическая область слева от 34)

  В Python критерий Манна-Уитни реализуется схожим образом, просто в нём считается p-value (приближённое или точное), 
единственное, в выдаче на первом месте – не $U$ как выше (минимальное из двух), а $U_1$.

```{python}
from scipy import stats
  stats.mannwhitneyu([8.48, 8.81, 9.10, 9.08, 8.39, 8.31, 8.94, 8.48, 7.95, 8.22, 8.13], 
                   [9.36, 8.92, 8.63, 9.19, 7.82, 8.04, 8.31, 8.38, 7.64, 8.99, 8.33], 
                   alternative = "two-sided")
```
